{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from models import generator, discriminator, flownet, initialize_flownet\n",
    "from loss_functions import intensity_loss, gradient_loss\n",
    "from v_utils import DataLoader, load, save, psnr_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'vessel'\n",
    "train_folder = '/dmount/Vessel/drawing_anno/Patient/train/image'\n",
    "train_gtfolder = '/dmount/Vessel/drawing_anno/Patient/train/label'\n",
    "test_folder = '/dmount/Vessel/drawing_anno/Patient/vessel/30_2_in'\n",
    "test_gtfolder = '/dmount/Vessel/drawing_anno/Patient/vessel/30_2_out'\n",
    "\n",
    "batch_size = 4\n",
    "iterations = 10000\n",
    "height, width = 256, 256\n",
    "\n",
    "\n",
    "l_num = 2\n",
    "alpha_num = 1\n",
    "lam_lp = 1.0\n",
    "lam_gdl = 1.0\n",
    "num_his = 1\n",
    "\n",
    "summary_dir = 'v_summary'\n",
    "snapshot_dir = 'v_snapshot'\n",
    "\n",
    "lr_bounds = [7000]\n",
    "lr = [0.0001, 1e-05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-42b5ab3ae89a>:6: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "train inputs = Tensor(\"dataset/strided_slice:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
      "train prediction gt = Tensor(\"dataset/strided_slice_1:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
      "test inputs = Tensor(\"dataset/strided_slice_2:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
      "test prediction gt = Tensor(\"dataset/strided_slice_3:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
      "training = generator\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /myGit/ano_pred_cvpr2018/Codes/v_utils.py:92: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /myGit/ano_pred_cvpr2018/Codes/v_utils.py:73: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "testing = generator\n"
     ]
    }
   ],
   "source": [
    "# define dataset\n",
    "with tf.name_scope('dataset'):\n",
    "    train_loader = DataLoader(train_folder, train_gtfolder, resize_h=height, resize_w=width)\n",
    "    train_dataset = train_loader(batch_size=batch_size)\n",
    "\n",
    "    train_it = train_dataset.make_one_shot_iterator()\n",
    "    train_data = train_it.get_next()\n",
    "    #train_data = train_data.set_shape([batch_size, height, width, 6])\n",
    "\n",
    "    train_inputs = train_data[...,:3]\n",
    "    train_gt = train_data[...,3:]\n",
    "\n",
    "    print('train inputs = {}'.format(train_inputs))\n",
    "    print('train prediction gt = {}'.format(train_gt))\n",
    "\n",
    "    \n",
    "    test_loader = DataLoader(test_folder, test_gtfolder, resize_h=height, resize_w=width)\n",
    "    test_dataset = test_loader(batch_size=batch_size)\n",
    "    \n",
    "    test_it = test_dataset.make_one_shot_iterator()\n",
    "    test_data = test_it.get_next()\n",
    "    #test_data = test_data.set_shape([batch_size, height, width, 6])\n",
    "\n",
    "    test_inputs = test_data[...,:3]\n",
    "    test_gt = test_data[...,3:]\n",
    "\n",
    "    print('test inputs = {}'.format(test_inputs))\n",
    "    print('test prediction gt = {}'.format(test_gt))\n",
    "\n",
    "# define training generator function\n",
    "with tf.variable_scope('generator', reuse=None):\n",
    "    print('training = {}'.format(tf.get_variable_scope().name))\n",
    "    train_outputs = generator(train_inputs, layers=4, output_channel=3)\n",
    "    train_psnr_error = psnr_error(gen_frames=train_outputs, gt_frames=train_gt)\n",
    "\n",
    "# define testing generator function\n",
    "with tf.variable_scope('generator', reuse=True):\n",
    "    print('testing = {}'.format(tf.get_variable_scope().name))\n",
    "    test_outputs = generator(test_inputs, layers=4, output_channel=3)\n",
    "    test_psnr_error = psnr_error(gen_frames=test_outputs, gt_frames=test_gt)\n",
    "\n",
    "\n",
    "# define intensity loss\n",
    "if lam_lp != 0:\n",
    "    lp_loss = intensity_loss(gen_frames=train_outputs, gt_frames=train_gt, l_num=l_num)\n",
    "else:\n",
    "    lp_loss = tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# define gdl loss\n",
    "if lam_gdl != 0:\n",
    "    gdl_loss = gradient_loss(gen_frames=train_outputs, gt_frames=train_gt, alpha=alpha_num)\n",
    "else:\n",
    "    gdl_loss = tf.constant(0.0, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Init successfully!\n",
      "No checkpoint file found.\n",
      "Training generator...\n",
      "Training generator...\n",
      "Training generator...\n",
      "Training generator...\n",
      "Training generator...\n",
      "Finish successfully!\n",
      "INFO:tensorflow:v_snapshot/model.ckpt-4 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "The checkpoint has been created.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('training'):\n",
    "    g_loss = tf.add_n([lp_loss * lam_lp, gdl_loss * lam_gdl], name='g_loss')\n",
    "\n",
    "    g_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='g_step')\n",
    "    g_lrate = tf.train.piecewise_constant(g_step, boundaries=lr_bounds, values=lr)\n",
    "    g_optimizer = tf.train.AdamOptimizer(learning_rate=g_lrate, name='g_optimizer')\n",
    "    g_vars = tf.get_collection(key=tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "\n",
    "    g_train_op = g_optimizer.minimize(g_loss, global_step=g_step, var_list=g_vars, name='g_train_op')\n",
    "\n",
    "\n",
    "# add all to summaries\n",
    "tf.summary.scalar(tensor=train_psnr_error, name='train_psnr_error')\n",
    "tf.summary.scalar(tensor=test_psnr_error, name='test_psnr_error')\n",
    "tf.summary.scalar(tensor=g_loss, name='g_loss')\n",
    "tf.summary.image(tensor=train_outputs, name='train_outputs')\n",
    "tf.summary.image(tensor=train_gt, name='train_gt')\n",
    "tf.summary.image(tensor=test_outputs, name='test_outputs')\n",
    "tf.summary.image(tensor=test_gt, name='test_gt')\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    # summaries\n",
    "    summary_writer = tf.summary.FileWriter(summary_dir, graph=sess.graph)\n",
    "\n",
    "    # initialize weights\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Init successfully!')\n",
    "\n",
    "\n",
    "    # tf saver\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=None)\n",
    "    restore_var = [v for v in tf.global_variables()]\n",
    "    loader = tf.train.Saver(var_list=restore_var)\n",
    "    if os.path.isdir(snapshot_dir):\n",
    "        ckpt = tf.train.get_checkpoint_state(snapshot_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            load(loader, sess, ckpt.model_checkpoint_path)\n",
    "        else:\n",
    "            print('No checkpoint file found.')\n",
    "    else:\n",
    "        load(loader, sess, snapshot_dir)\n",
    "\n",
    "    _step, _loss, _summaries = 0, None, None\n",
    "    while _step < iterations:\n",
    "        try:\n",
    "\n",
    "            print('Training generator...')\n",
    "            _, _g_lr, _step, _lp_loss, _gdl_loss, _g_loss, _train_psnr, _summaries = sess.run(\n",
    "                [g_train_op, g_lrate, g_step, lp_loss, gdl_loss, g_loss, train_psnr_error, summary_op])\n",
    "\n",
    "            if _step % 10 == 0:\n",
    "                print('GeneratorModel : Step {}, lr = {:.6f}'.format(_step, _g_lr))\n",
    "                print('                 Global      Loss : ', _g_loss)\n",
    "                print('                 intensity   Loss : ({:.4f} * {:.4f} = {:.4f})'.format(_lp_loss, lam_lp, _lp_loss * lam_lp))\n",
    "                print('                 gradient    Loss : ({:.4f} * {:.4f} = {:.4f})'.format( _gdl_loss, lam_gdl, _gdl_loss * lam_gdl))\n",
    "                print('                 PSNR  Error      : ', _train_psnr)\n",
    "            if _step % 100 == 0:\n",
    "                summary_writer.add_summary(_summaries, global_step=_step)\n",
    "                print('Save summaries...')\n",
    "\n",
    "            if _step % 1000 == 0:\n",
    "                save(saver, sess, snapshot_dir, _step)\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Finish successfully!')\n",
    "            save(saver, sess, snapshot_dir, _step)\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
