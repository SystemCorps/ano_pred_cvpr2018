{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from models import generator, discriminator, flownet, initialize_flownet\n",
    "from loss_functions import intensity_loss, gradient_loss\n",
    "from utils import DataLoader, load, save, psnr_error\n",
    "from constant import const\n",
    "\n",
    "\n",
    "os.environ['CUDA_DEVICES_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = const.GPU\n",
    "\n",
    "dataset_name = const.DATASET\n",
    "train_folder = const.TRAIN_FOLDER\n",
    "test_folder = const.TEST_FOLDER\n",
    "\n",
    "batch_size = const.BATCH_SIZE\n",
    "iterations = const.ITERATIONS\n",
    "num_his = const.NUM_HIS\n",
    "height, width = 256, 256\n",
    "flow_height, flow_width = const.FLOW_HEIGHT, const.FLOW_WIDTH\n",
    "\n",
    "l_num = const.L_NUM\n",
    "alpha_num = const.ALPHA_NUM\n",
    "lam_lp = const.LAM_LP\n",
    "lam_gdl = const.LAM_GDL\n",
    "lam_adv = const.LAM_ADV\n",
    "lam_flow = const.LAM_FLOW\n",
    "adversarial = (lam_adv != 0)\n",
    "\n",
    "summary_dir = const.SUMMARY_DIR\n",
    "snapshot_dir = const.SNAPSHOT_DIR\n",
    "\n",
    "\n",
    "\n",
    "print(const)\n",
    "\n",
    "# define dataset\n",
    "with tf.name_scope('dataset'):\n",
    "    train_loader = DataLoader(train_folder, resize_height=height, resize_width=width)\n",
    "    train_dataset = train_loader(batch_size=batch_size, time_steps=num_his, num_pred=1)\n",
    "\n",
    "    train_it = train_dataset.make_one_shot_iterator()\n",
    "    train_videos_clips_tensor = train_it.get_next()\n",
    "    train_videos_clips_tensor.set_shape([batch_size, height, width, 3*(num_his + 1)])\n",
    "\n",
    "    train_inputs = train_videos_clips_tensor[..., 0:num_his*3]\n",
    "    train_gt = train_videos_clips_tensor[..., -3:]\n",
    "\n",
    "    print('train inputs = {}'.format(train_inputs))\n",
    "    print('train prediction gt = {}'.format(train_gt))\n",
    "\n",
    "    test_loader = DataLoader(test_folder, resize_height=height, resize_width=width)\n",
    "    test_dataset = test_loader(batch_size=batch_size, time_steps=num_his, num_pred=1)\n",
    "    test_it = test_dataset.make_one_shot_iterator()\n",
    "    test_videos_clips_tensor = test_it.get_next()\n",
    "    test_videos_clips_tensor.set_shape([batch_size, height, width, 3*(num_his + 1)])\n",
    "\n",
    "    test_inputs = test_videos_clips_tensor[..., 0:num_his*3]\n",
    "    test_gt = test_videos_clips_tensor[..., -3:]\n",
    "\n",
    "    print('test inputs = {}'.format(test_inputs))\n",
    "    print('test prediction gt = {}'.format(test_gt))\n",
    "\n",
    "# define training generator function\n",
    "with tf.variable_scope('generator', reuse=None):\n",
    "    print('training = {}'.format(tf.get_variable_scope().name))\n",
    "    train_outputs = generator(train_inputs, layers=4, output_channel=3)\n",
    "    train_psnr_error = psnr_error(gen_frames=train_outputs, gt_frames=train_gt)\n",
    "\n",
    "# define testing generator function\n",
    "with tf.variable_scope('generator', reuse=True):\n",
    "    print('testing = {}'.format(tf.get_variable_scope().name))\n",
    "    test_outputs = generator(test_inputs, layers=4, output_channel=3)\n",
    "    test_psnr_error = psnr_error(gen_frames=test_outputs, gt_frames=test_gt)\n",
    "\n",
    "\n",
    "# define intensity loss\n",
    "if lam_lp != 0:\n",
    "    lp_loss = intensity_loss(gen_frames=train_outputs, gt_frames=train_gt, l_num=l_num)\n",
    "else:\n",
    "    lp_loss = tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# define gdl loss\n",
    "if lam_gdl != 0:\n",
    "    gdl_loss = gradient_loss(gen_frames=train_outputs, gt_frames=train_gt, alpha=alpha_num)\n",
    "else:\n",
    "    gdl_loss = tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# define flow loss\n",
    "if lam_flow != 0:\n",
    "    train_gt_flow = flownet(input_a=train_inputs[..., -3:], input_b=train_gt,\n",
    "                            height=flow_height, width=flow_width, reuse=None)\n",
    "    train_pred_flow = flownet(input_a=train_inputs[..., -3:], input_b=train_outputs,\n",
    "                              height=flow_height, width=flow_width, reuse=True)\n",
    "    flow_loss = tf.reduce_mean(tf.abs(train_gt_flow - train_pred_flow))\n",
    "else:\n",
    "    flow_loss = tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# define adversarial loss\n",
    "if adversarial:\n",
    "    with tf.variable_scope('discriminator', reuse=None):\n",
    "        real_logits, real_outputs = discriminator(inputs=train_gt)\n",
    "    with tf.variable_scope('discriminator', reuse=True):\n",
    "        fake_logits, fake_outputs = discriminator(inputs=train_outputs)\n",
    "\n",
    "    print('real_outputs = {}'.format(real_outputs))\n",
    "    print('fake_outputs = {}'.format(fake_outputs))\n",
    "\n",
    "    adv_loss = tf.reduce_mean(tf.square(fake_outputs - 1) / 2)\n",
    "    dis_loss = tf.reduce_mean(tf.square(real_outputs - 1) / 2) + tf.reduce_mean(tf.square(fake_outputs) / 2)\n",
    "else:\n",
    "    adv_loss = tf.constant(0.0, dtype=tf.float32)\n",
    "    dis_loss = tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "with tf.name_scope('training'):\n",
    "    g_loss = tf.add_n([lp_loss * lam_lp, gdl_loss * lam_gdl, adv_loss * lam_adv, flow_loss * lam_flow], name='g_loss')\n",
    "\n",
    "    g_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='g_step')\n",
    "    g_lrate = tf.train.piecewise_constant(g_step, boundaries=const.LRATE_G_BOUNDARIES, values=const.LRATE_G)\n",
    "    g_optimizer = tf.train.AdamOptimizer(learning_rate=g_lrate, name='g_optimizer')\n",
    "    g_vars = tf.get_collection(key=tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "\n",
    "    g_train_op = g_optimizer.minimize(g_loss, global_step=g_step, var_list=g_vars, name='g_train_op')\n",
    "\n",
    "    if adversarial:\n",
    "        # training discriminator\n",
    "        d_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='d_step')\n",
    "        d_lrate = tf.train.piecewise_constant(d_step, boundaries=const.LRATE_D_BOUNDARIES, values=const.LRATE_D)\n",
    "        d_optimizer = tf.train.AdamOptimizer(learning_rate=d_lrate, name='g_optimizer')\n",
    "        d_vars = tf.get_collection(key=tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "\n",
    "        d_train_op = d_optimizer.minimize(dis_loss, global_step=d_step, var_list=d_vars, name='d_optimizer')\n",
    "    else:\n",
    "        d_step = None\n",
    "        d_lrate = None\n",
    "        d_train_op = None\n",
    "\n",
    "# add all to summaries\n",
    "tf.summary.scalar(tensor=train_psnr_error, name='train_psnr_error')\n",
    "tf.summary.scalar(tensor=test_psnr_error, name='test_psnr_error')\n",
    "tf.summary.scalar(tensor=g_loss, name='g_loss')\n",
    "tf.summary.scalar(tensor=adv_loss, name='adv_loss')\n",
    "tf.summary.scalar(tensor=dis_loss, name='dis_loss')\n",
    "tf.summary.image(tensor=train_outputs, name='train_outputs')\n",
    "tf.summary.image(tensor=train_gt, name='train_gt')\n",
    "tf.summary.image(tensor=test_outputs, name='test_outputs')\n",
    "tf.summary.image(tensor=test_gt, name='test_gt')\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    # summaries\n",
    "    summary_writer = tf.summary.FileWriter(summary_dir, graph=sess.graph)\n",
    "\n",
    "    # initialize weights\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Init successfully!')\n",
    "\n",
    "    if lam_flow != 0:\n",
    "        # initialize flownet\n",
    "        initialize_flownet(sess, const.FLOWNET_CHECKPOINT)\n",
    "\n",
    "    # tf saver\n",
    "    saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=None)\n",
    "    restore_var = [v for v in tf.global_variables()]\n",
    "    loader = tf.train.Saver(var_list=restore_var)\n",
    "    if os.path.isdir(snapshot_dir):\n",
    "        ckpt = tf.train.get_checkpoint_state(snapshot_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            load(loader, sess, ckpt.model_checkpoint_path)\n",
    "        else:\n",
    "            print('No checkpoint file found.')\n",
    "    else:\n",
    "        load(loader, sess, snapshot_dir)\n",
    "\n",
    "    _step, _loss, _summaries = 0, None, None\n",
    "    while _step < iterations:\n",
    "        try:\n",
    "            if adversarial:\n",
    "                print('Training discriminator...')\n",
    "                _, _d_lr, _d_step, _dis_loss = sess.run([d_train_op, d_lrate, d_step, dis_loss])\n",
    "            else:\n",
    "                _d_step = 0\n",
    "                _d_lr = 0\n",
    "                _dis_loss = 0\n",
    "\n",
    "            print('Training generator...')\n",
    "            _, _g_lr, _step, _lp_loss, _gdl_loss, _adv_loss, _flow_loss, _g_loss, _train_psnr, _summaries = sess.run(\n",
    "                [g_train_op, g_lrate, g_step, lp_loss, gdl_loss, adv_loss, flow_loss, g_loss, train_psnr_error, summary_op])\n",
    "\n",
    "            if _step % 10 == 0:\n",
    "                print('DiscriminatorModel: Step {} | Global Loss: {:.6f}, lr = {:.6f}'.format(_d_step, _dis_loss, _d_lr))\n",
    "                print('GeneratorModel : Step {}, lr = {:.6f}'.format(_step, _g_lr))\n",
    "                print('                 Global      Loss : ', _g_loss)\n",
    "                print('                 intensity   Loss : ({:.4f} * {:.4f} = {:.4f})'.format(_lp_loss, lam_lp, _lp_loss * lam_lp))\n",
    "                print('                 gradient    Loss : ({:.4f} * {:.4f} = {:.4f})'.format( _gdl_loss, lam_gdl, _gdl_loss * lam_gdl))\n",
    "                print('                 adversarial Loss : ({:.4f} * {:.4f} = {:.4f})'.format(_adv_loss, lam_adv, _adv_loss * lam_adv))\n",
    "                print('                 flownet     Loss : ({:.4f} * {:.4f} = {:.4f})'.format(_flow_loss, lam_flow, _flow_loss * lam_flow))\n",
    "                print('                 PSNR  Error      : ', _train_psnr)\n",
    "            if _step % 100 == 0:\n",
    "                summary_writer.add_summary(_summaries, global_step=_step)\n",
    "                print('Save summaries...')\n",
    "\n",
    "            if _step % 1000 == 0:\n",
    "                save(saver, sess, snapshot_dir, _step)\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Finish successfully!')\n",
    "            save(saver, sess, snapshot_dir, _step)\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
