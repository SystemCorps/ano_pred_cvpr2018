{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting v_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%file v_utils.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "def np_load_frame(filename, resize_height, resize_width):\n",
    "    \"\"\"\n",
    "    Load image path and convert it to numpy.ndarray. Notes that the color channels are BGR and the color space\n",
    "    is normalized from [0, 255] to [-1, 1].\n",
    "\n",
    "    :param filename: the full path of image\n",
    "    :param resize_height: resized height\n",
    "    :param resize_width: resized width\n",
    "    :return: numpy.ndarray\n",
    "    \"\"\"\n",
    "    image_decoded = cv2.imread(filename)\n",
    "    image_resized = cv2.resize(image_decoded, (resize_width, resize_height))\n",
    "    image_resized = image_resized.astype(dtype=np.float32)\n",
    "    image_resized = (image_resized / 127.5) - 1.0\n",
    "    return image_resized\n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, infolder, gtfolder, resize_h=256, resize_w=256):\n",
    "        self.indir = infolder\n",
    "        self.gtdir = gtfolder\n",
    "        self.resize_h = resize_h\n",
    "        self.resize_w = resize_w\n",
    "        \n",
    "        self.inImgs = glob.glob(os.path.join(self.indir, '*.jpg'))\n",
    "        self.inImgs.sort()\n",
    "        self.gtImgs = glob.glob(os.path.join(self.gtdir, '*.jpg'))\n",
    "        self.gtImgs.sort()\n",
    "        \n",
    "    \n",
    "    def __call__(self, batch_size):\n",
    "        inImgs = self.inImgs\n",
    "        gtImgs = self.gtImgs\n",
    "        \n",
    "        \n",
    "        re_h = self.resize_h\n",
    "        re_w = self.resize_w\n",
    "        \n",
    "        def img_gen():\n",
    "            for i in range(len(inImgs)):\n",
    "                inImg = np_load_frame(inImgs[i], re_h, re_w)\n",
    "                gtImg = np_load_frame(gtImgs[i], re_h, re_w)\n",
    "                \n",
    "                trImg = np.concatenate((inImg, gtImg), axis=2)\n",
    "            \n",
    "                yield trImg\n",
    "                \n",
    "        dataset = tf.data.Dataset.from_generator(generator=img_gen,\n",
    "                                                output_types=tf.float32,\n",
    "                                                output_shapes=[re_h, re_w, 6])\n",
    "        \n",
    "        data = dataset.batch(batch_size)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    \n",
    "def log10(t):\n",
    "    \"\"\"\n",
    "    Calculates the base-10 log of each element in t.\n",
    "\n",
    "    @param t: The tensor from which to calculate the base-10 log.\n",
    "\n",
    "    @return: A tensor with the base-10 log of each element in t.\n",
    "    \"\"\"\n",
    "\n",
    "    numerator = tf.log(t)\n",
    "    denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def psnr_error(gen_frames, gt_frames):\n",
    "    \"\"\"\n",
    "    Computes the Peak Signal to Noise Ratio error between the generated images and the ground\n",
    "    truth images.\n",
    "\n",
    "    @param gen_frames: A tensor of shape [batch_size, height, width, 3]. The frames generated by the\n",
    "                       generator model.\n",
    "    @param gt_frames: A tensor of shape [batch_size, height, width, 3]. The ground-truth frames for\n",
    "                      each frame in gen_frames.\n",
    "\n",
    "    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the\n",
    "             batch.\n",
    "    \"\"\"\n",
    "    shape = tf.shape(gen_frames)\n",
    "    num_pixels = tf.to_float(shape[1] * shape[2] * shape[3])\n",
    "    gt_frames = (gt_frames + 1.0) / 2.0\n",
    "    gen_frames = (gen_frames + 1.0) / 2.0\n",
    "    square_diff = tf.square(gt_frames - gen_frames)\n",
    "\n",
    "    batch_errors = 10 * log10(1 / ((1 / num_pixels) * tf.reduce_sum(square_diff, [1, 2, 3])))\n",
    "    return tf.reduce_mean(batch_errors)\n",
    "\n",
    "\n",
    "\n",
    "def diff_mask(gen_frames, gt_frames, min_value=-1, max_value=1):\n",
    "    # normalize to [0, 1]\n",
    "    delta = max_value - min_value\n",
    "    gen_frames = (gen_frames - min_value) / delta\n",
    "    gt_frames = (gt_frames - min_value) / delta\n",
    "\n",
    "    gen_gray_frames = tf.image.rgb_to_grayscale(gen_frames)\n",
    "    gt_gray_frames = tf.image.rgb_to_grayscale(gt_frames)\n",
    "\n",
    "    diff = tf.abs(gen_gray_frames - gt_gray_frames)\n",
    "    return diff\n",
    "\n",
    "\n",
    "def load(saver, sess, ckpt_path):\n",
    "    saver.restore(sess, ckpt_path)\n",
    "    print(\"Restored model parameters from {}\".format(ckpt_path))\n",
    "\n",
    "\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print('The checkpoint has been created.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
